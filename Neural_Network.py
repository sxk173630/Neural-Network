# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TUBqWWZSvemAU5SjLU_tBkuwrEjyS7b4
"""

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler

from sklearn.preprocessing import OneHotEncoder

from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score

#A source library that provides the activation function for neural networks.
import keras

from keras.models import Sequential

from keras.layers import Dense

df = pd.read_csv("/content/drive/My Drive/train.csv")

df

#Orginazing the vals from train using iloc.
X = df.iloc[:,:20].values
y = df.iloc[:,20:21].values

#dropping all null vals from the dataframe.
df = df.dropna()

#Standardizes the features by subtracting the mean and scaling to unit variance.
sc = StandardScaler()

X = sc.fit_transform(X)

#A function that uses an inputted matrix of integers and then outputs a matrix that organizes the columns to one value of one feature.
ohe = OneHotEncoder()

y = ohe.fit_transform(y).toarray()

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)

#Creates a sequential model from the keras package.
model = Sequential()

#Activation functions:
model.add(Dense(16, input_dim=20, activation ='relu'))
model.add(Dense(12, activation= 'relu'))
model.add(Dense(4, activation='softmax'))

#A data compiler that uses an optimizer from keras package.
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

#A class that gropus layers into an object after training from keras package.
training = model.fit(X_train, y_train, epochs=80, batch_size=50)

y_pred = model.predict(X_test)

#Labeling the predictions.
pred = list()
for i in range(len(y_pred)):
    pred.append(np.argmax(y_pred[i]))

#Converting Onehotencoded test label to label.
test = list()
for i in range(len(y_test)):
    test.append(np.argmax(y_test[i]))

#Printing out the Accuracy Score of the test.
AccScore = accuracy_score(pred,test)
print('Accuracy =', AccScore*100)

training = model.fit(X_train, y_train,validation_data = (X_test,y_test), epochs=80, batch_size=100)

#Plotting the graph of the test vs train.
plt.title('Accuracy Graph')
plt.ylabel('Accuracy of passes')
plt.xlabel('Epoch(number of passes)')
plt.plot(training.history['val_accuracy'])
plt.plot(training.history['accuracy'])
plt.legend(['Train', 'Test'], loc='center right')
plt.show()